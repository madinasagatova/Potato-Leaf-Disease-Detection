{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bab4b6-3388-49bb-b2cc-a319113179a3",
   "metadata": {},
   "source": [
    "# MSC_DA_CA1_Semester_2:\n",
    "# A Comparative Study of VGG16 and EfficientNet for Potato Leaf Disease Detection: An Integration of Hadoop and Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0427a-4315-47b8-8f37-8aeb64585479",
   "metadata": {},
   "source": [
    "**Name:**\n",
    "Madina Sagatova\n",
    "\n",
    "**Student ID:**\n",
    "2021255\n",
    "\n",
    "**Student email:**\n",
    "2021255@student.cct.ie\n",
    "\n",
    "**Programme Title:**\n",
    "MSc in Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c3112f",
   "metadata": {},
   "source": [
    "### Loading Image Dataset with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8ed7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 21:28:02 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               image|\n",
      "+--------------------+\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "|{hdfs://localhost...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session \n",
    "spark = SparkSession.builder.appName('PotatoLeafDiseas').getOrCreate()\n",
    "\n",
    "# Loading the images from HDFS \n",
    "data = spark.read.format('image').load('hdfs://localhost:9000/user1/potato_disease/*')\n",
    "\n",
    "# Displaying schema to ensure the data is loaded correctly \n",
    "data.printSchema()\n",
    "\n",
    "# Show some sample data\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ae588",
   "metadata": {},
   "source": [
    "### Label & Preprocess Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea37d401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              origin|               label|\n",
      "+--------------------+--------------------+\n",
      "|hdfs://localhost:...|Potato___Early_bl...|\n",
      "|hdfs://localhost:...|Potato___Early_bl...|\n",
      "|hdfs://localhost:...|    Potato___healthy|\n",
      "|hdfs://localhost:...|    Potato___healthy|\n",
      "|hdfs://localhost:...|    Potato___healthy|\n",
      "|hdfs://localhost:...|Potato___Early_bl...|\n",
      "|hdfs://localhost:...|    Potato___healthy|\n",
      "|hdfs://localhost:...|    Potato___healthy|\n",
      "|hdfs://localhost:...|Potato___Early_bl...|\n",
      "|hdfs://localhost:...|    Potato___healthy|\n",
      "|hdfs://localhost:...|    Potato___healthy|\n",
      "|hdfs://localhost:...|    Potato___healthy|\n",
      "|hdfs://localhost:...|Potato___Early_bl...|\n",
      "|hdfs://localhost:...|Potato___Early_bl...|\n",
      "|hdfs://localhost:...|    Potato___healthy|\n",
      "+--------------------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "# Add a label column based on the 3 folder names: Potato___Early_blight, Potato___healthy, Potato___Late_blight\n",
    "data = data.withColumn('label',regexp_extract(col('image.origin'), 'potato_disease/([^/]+)', 1))\n",
    "\n",
    "# Show some labeled data\n",
    "data.select('image.origin', 'label').show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecca8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
